import 'dart:io';
import 'package:flutter_ai_kit/flutter_ai_kit.dart';
import 'package:tflite_flutter/tflite_flutter.dart';

import 'model_manager.dart';

/// TFLite ProvideråŸºç±»
///
/// æä¾›TensorFlow Liteæ¨¡å‹æ¨ç†çš„é€šç”¨èƒ½åŠ›
///
/// ç¤ºä¾‹:
/// ```dart
/// class MyTFLiteProvider extends TFLiteProvider<String, Map<String, dynamic>> {
///   MyTFLiteProvider({required super.modelId})
///       : super(
///           supportedTaskType: 'my_task',
///           inputPreprocessor: (input) => _preprocess(input),
///           outputParser: (output) => _parse(output),
///         );
/// }
/// ```
abstract class TFLiteProvider<TInput, TOutput>
    implements AIProvider<TInput, TOutput> {
  @override
  String get id => 'tflite_$modelId';

  @override
  AIProviderType get type => AIProviderType.local;

  @override
  bool get requiresNetwork => false;

  /// æ¨¡å‹ID
  final String modelId;

  /// æ”¯æŒçš„ä»»åŠ¡ç±»å‹
  final String supportedTaskType;

  /// è¾“å…¥é¢„å¤„ç†å‡½æ•°
  final List<Object> Function(TInput input) inputPreprocessor;

  /// è¾“å‡ºè§£æå‡½æ•°
  final TOutput Function(List<Object?> output) outputParser;

  /// æ¨¡å‹ç®¡ç†å™¨
  final ModelManager _modelManager;

  /// TFLiteè§£é‡Šå™¨ï¼ˆæ‡’åŠ è½½ï¼‰
  Interpreter? _interpreter;

  TFLiteProvider({
    required this.modelId,
    required this.supportedTaskType,
    required this.inputPreprocessor,
    required this.outputParser,
    ModelManager? modelManager,
  }) : _modelManager = modelManager ?? ModelManager();

  @override
  bool supportsTask(String taskType) => taskType == supportedTaskType;

  @override
  Future<bool> isReady() async {
    return await _modelManager.isModelDownloaded(modelId);
  }

  @override
  Future<AIResult<TOutput>> execute(AITask<TInput, TOutput> task) async {
    final startTime = DateTime.now();

    try {
      // 1. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
      if (!await isReady()) {
        return AIResult.failure(
          'æ¨¡å‹æœªä¸‹è½½: $modelId',
          DateTime.now().difference(startTime),
          metadata: AIResultMetadata(providerName: name),
        );
      }

      // 2. æ‡’åŠ è½½æ¨¡å‹
      if (_interpreter == null) {
        await _loadModel();
      }

      // 3. é¢„å¤„ç†è¾“å…¥
      final input = inputPreprocessor(task.input);

      // 4. æ¨ç†
      final output = await _runInference(input);

      // 5. è§£æè¾“å‡º
      final result = outputParser(output);

      return AIResult.success(
        result,
        DateTime.now().difference(startTime),
        metadata: AIResultMetadata(
          providerName: name,
          modelName: modelId,
        ),
      );
    } catch (e) {
      return AIResult.failure(
        e.toString(),
        DateTime.now().difference(startTime),
        metadata: AIResultMetadata(providerName: name),
      );
    }
  }

  @override
  Future<double> estimateCost(AITask<TInput, TOutput> task) async => 0.0;

  /// åŠ è½½æ¨¡å‹
  Future<void> _loadModel() async {
    final modelPath = await _modelManager.getModelPath(modelId);
    print('ğŸ“¦ [TFLiteProvider] åŠ è½½æ¨¡å‹: $modelPath');

    _interpreter = await Interpreter.fromFile(File(modelPath));

    print('âœ… [TFLiteProvider] æ¨¡å‹å·²åŠ è½½');
    print('   è¾“å…¥å½¢çŠ¶: ${_interpreter!.getInputTensors().map((t) => t.shape)}');
    print('   è¾“å‡ºå½¢çŠ¶: ${_interpreter!.getOutputTensors().map((t) => t.shape)}');
  }

  /// è¿è¡Œæ¨ç†
  Future<List<Object?>> _runInference(List<Object> input) async {
    if (_interpreter == null) {
      throw Exception('Interpreter not initialized');
    }

    // åˆ›å»ºè¾“å‡ºç¼“å†²åŒº
    final outputTensors = _interpreter!.getOutputTensors();
    final outputs = List<Object?>.filled(outputTensors.length, null);

    for (int i = 0; i < outputTensors.length; i++) {
      final shape = outputTensors[i].shape;
      final type = outputTensors[i].type;

      // æ ¹æ®ç±»å‹åˆ›å»ºè¾“å‡ºç¼“å†²åŒº
      // ç®€åŒ–å¤„ç†ï¼šç›´æ¥åˆ›å»ºç©ºåˆ—è¡¨ï¼Œè®©æ¨ç†å¼•æ“å¡«å……
      final size = shape.reduce((a, b) => a * b);
      outputs[i] = List.filled(size, 0.0);
    }

    // è¿è¡Œæ¨ç†
    _interpreter!.run(input, outputs);

    return outputs;
  }

  /// é‡Šæ”¾èµ„æº
  void dispose() {
    _interpreter?.close();
    _interpreter = null;
  }
}
